{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os → lets you interact with the operating system (e.g., read environment variables, list files).\nimport os\n# import json → allows working with JSON (JavaScript Object Notation) data, which is often used for APIs.\nimport json\n# loads the Pandas library (used for data analysis, reading CSV/Excel).\nimport pandas as pd\n# import traceback → lets you capture and format error messages. Eg : inside try/except, you can do traceback.print_exc() to print the full error stack.\nimport traceback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''Imports the ChatOpenAI class from LangChain (a library to work with LLMs like GPT).\n    ChatOpenAI is used to connect with OpenAI’s models.\n    Example: If you want GPT to answer, you’ll create a ChatOpenAI object.'''\nfrom langchain.chat_models import ChatOpenAI","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''dotenv is used to load sensitive data (like API keys) from a .env file instead of hardcoding them.\n   load_dotenv() → automatically loads variables into your Python environment.'''\n\nfrom dotenv import load_dotenv\n\nload_dotenv()  # take environment variables from .env.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''Reads the environment variable named my-openkey into the Python variable KEY.\n   KEY will now hold your OpenAI API key.'''\n\nKEY=os.getenv(\"my-openkey\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''Creates an LLM object (chatbot connection).\n   openai_api_key=KEY → uses your API key.\n   model_name=\"gpt-3.5-turbo\" → tells which OpenAI model to use.\n   temperature=0.5 → controls creativity.\n   0.0 → deterministic answers (less creativity).\n   1.0 → more randomness.'''\n\nllm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\", temperature=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For to Inspect the object\nllm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OpenAI → used for completion-style models like text-davinci-003. These expect plain text input and return plain text.\n# Eg : If you want a chat with roles (system, user), you use ChatOpenAI.| If you just want “I give text → model gives text,” you use OpenAI.\nfrom langchain.llms import OpenAI\n# Lets you create templates for prompts where you can fill in blanks.\nfrom langchain.prompts import PromptTemplate\n# Combines a PromptTemplate + LLM into a single unit (called a chain).| You can pass inputs, and it automatically builds the prompt → sends to LLM → gives output.\nfrom langchain.chains import LLMChain\n# Lets you connect multiple chains together.| Output of Chain 1 → becomes input of Chain 2 → … and so on.\nfrom langchain.chains import SequentialChain\n# This is for tracking token usage and cost when you call the LLM.| Useful if you want to know how much money a request costs.\nfrom langchain.callbacks import get_openai_callback\n# A library for working with PDF files (reading text, pages, metadata).\nimport PyPDF2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# RESPONSE_JSON is just a format guide → it tells the AI exactly how to structure quiz questions (with question, options, and correct answer).\n\nRESPONSE_JSON = {\n    \"1\": {\n        \"mcq\": \"multiple choice question\",\n        \"options\": {\n            \"a\": \"choice here\",\n            \"b\": \"choice here\",\n            \"c\": \"choice here\",\n            \"d\": \"choice here\",\n        },\n        \"correct\": \"correct answer\",\n    },\n    \"2\": {\n        \"mcq\": \"multiple choice question\",\n        \"options\": {\n            \"a\": \"choice here\",\n            \"b\": \"choice here\",\n            \"c\": \"choice here\",\n            \"d\": \"choice here\",\n        },\n        \"correct\": \"correct answer\",\n    },\n    \"3\": {\n        \"mcq\": \"multiple choice question\",\n        \"options\": {\n            \"a\": \"choice here\",\n            \"b\": \"choice here\",\n            \"c\": \"choice here\",\n            \"d\": \"choice here\",\n        },\n        \"correct\": \"correct answer\",\n    },\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TEMPLATE is the instruction message for the AI.| the AI knows what to do and how to format the answer.\n\nTEMPLATE=\"\"\"\nText:{text}\nYou are an expert MCQ maker. Given the above text, it is your job to \\\ncreate a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\nEnsure to make {number} MCQs\n### RESPONSE_JSON\n{response_json}\n\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''PromptTemplate(...) wraps our template into a reusable object.\n   You just give it the variables → it builds the correct instruction text for the AI.\n   Later, it can be directly combined with LLMChain to generate quizzes.'''\n\nquiz_generation_prompt = PromptTemplate(\n    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n    template=TEMPLATE\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# now quiz_chain is ready to generate MCQs by just passing in variables | this is the first chain \nquiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TEMPLATE2=\"\"\"\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\nYou need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \nif the quiz is not at per with the cognitive and analytical abilities of the students,\\\nupdate the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\nQuiz_MCQs:\n{quiz}\n\nCheck from an expert English Writer of the above quiz:\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n                                        output_variables=[\"quiz\", \"review\"], verbose=True,)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_path=r\"/Users/muhammadsuleman/MCQGEN/Data.txt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(file_path, 'r') as file:\n    TEXT = file.read()\nprint(TEXT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Serialize the Python dictionary into a JSON-formatted string\njson.dumps(RESPONSE_JSON)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUMBER=5 \nSUBJECT=\"machine learning\"\nTONE=\"simple\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n\n#How to setup Token Usage Tracking in LangChain\nwith get_openai_callback() as cb:\n    response=generate_evaluate_chain(\n        {\n            \"text\": TEXT,\n            \"number\": NUMBER,\n            \"subject\":SUBJECT,\n            \"tone\": TONE,\n            \"response_json\": json.dumps(RESPONSE_JSON)\n        }\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total Number of Tokens used in API call:{cb.total_tokens}\")\nprint(f\"Total Number of Tokens used in prompts:{cb.prompt_tokens}\")\nprint(f\"Number of Tokens generated by the model in its response:{cb.completion_tokens}\")\nprint(f\"Cost of the API call based on tokens used:{cb.total_cost}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# .get(\"quiz\") will return the value associated with the key \"quiz\".\n# Converts a JSON string into a Python dictionary.\n\nquiz=response.get(\"quiz\")\nquiz=json.loads(quiz)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This will hold all the formatted quiz questions.\nquiz_table_data = []\n\nfor key, value in quiz.items():\n    mcq = value[\"mcq\"]\n    options = \" | \".join(\n        [\n            f\"{option}: {option_value}\"\n            for option, option_value in value[\"options\"].items()\n            ]\n        )\n    correct = value[\"correct\"]\n    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})\nquiz_table_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quiz=pd.DataFrame(quiz_table_data)\nquiz.to_csv(\"machinelearning.csv\",index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\ndatetime.now().strftime('%m_%d_%Y_%H_%M_%S')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}